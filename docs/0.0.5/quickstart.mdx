---
title: 'Quickstart'
description: 'Quickly start **monitoring** your **LLM Applications** in just **two lines** of code'
icon: 'bolt'
---

This guide will walk you through setting up your monitoring system with minimal effort. In just a few steps, you'll be able to track and analyze the performance and usage of your Large Language Model (LLM) applications.

## Prerequistes
- Ensure you have access to a **Kubernetes Cluster**. You can quickly spin up a Kubernetes Cluster using [Kind](https://github.com/kubernetes-sigs/kind?tab=readme-ov-file#installation-and-usage)

## Get Started

<Steps>
  <Step title="Install Doku in a Kubernetes Cluster">
    <Steps>
      <Step title="Helm Repo Setup">
      ```shell shell
      helm repo add dokulabs https://dokulabs.github.io/helm/
      helm repo update
      ```
      </Step>
      <Step title="Installing the Helm Chart">
      ```shell shell
      helm install doku dokulabs/doku
      ```
      </Step>
    </Steps>
  </Step>
  <Step title="Generate an API Key">
    With Doku running, the next step is to [generate an API key](/0.0.5/api-reference/endpoint/api-keys/create) for secure communication between your applications and Doku.

    To generate your first API key, you can use the following command:

    ```shell shell
    curl --request POST \
      --url https://<your-doku-url>/api/keys \
      --header 'Authorization: ""' \
      --header 'Content-Type: application/json' \
      --data '{
      "name": "Admin"
      }'
    ```

    Make sure to store the returned API key securely, as it's necessary for authorizing future API calls with Doku.

    <Info>
    During your initial request to generate an API key, you can leave the Authorization header empty (i.e., `""`). For subsequent requests, you will need to supply the generated API key.
    </Info>

  </Step>
  <Step title="Instrument your code">
    Choose the appropriate SDK for your application's programming language and follow the steps to integrate monitoring with just a couple of lines of code.
    <Tabs>
      <Tab title="Python">
        <Steps>
          <Step title="Install the dokumetry Python SDK using pip">
            ```shell
            pip install dokumetry
            ```
          </Step>
          <Step title="Add the following two lines to your application code:">
            Add the snippet below to your Python application, replacing `YOUR_DOKU_URL` and `YOUR_DOKU_TOKEN` with corresponding values.
            
            ```python
            import dokumetry

            dokumetry.init(llm=client, doku_url="YOUR_DOKU_URL", api_key="YOUR_DOKU_TOKEN")
            ```

            Example Usage for monitoring `OpenAI` Usage:

            ```python
            from openai import OpenAI
            import dokumetry

            client = OpenAI(
                api_key="YOUR_OPENAI_KEY"
            )

            # Pass the above `client` object along with your DOKU URL and API key and this will make sure that all OpenAI calls are automatically tracked.
            dokumetry.init(llm=client, doku_url="YOUR_DOKU_URL", api_key="YOUR_DOKU_TOKEN")

            chat_completion = client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": "What is LLM Observability",
                    }
                ],
                model="gpt-3.5-turbo",
            )
            ```
            
            Refer to the `dokumetry` [Python SDK repository](https://github.com/dokulabs/dokumetry-python) for more advanced configurations and use cases.
          </Step>
        </Steps>
      </Tab>
      <Tab title="NodeJS">
        <Steps>
          <Step title="Install the dokumetry NodeJS SDK using npm">
            ```shell
            npm install dokumetry
            ```
          </Step>
          <Step title="Add the following two lines to your application code">
            Add the snippet below to your NodeJS application, replacing `YOUR_DOKU_URL` and `YOUR_DOKU_TOKEN` with corresponding values.
            ```javascript
            import DokuMetry from 'dokumetry';

            DokuMetry.init({llm: openai, dokuUrl: "YOUR_DOKU_URL", apiKey: "YOUR_DOKU_TOKEN"})
            ```

            Example Usage for monitoring `OpenAI` Usage:

            ```javascript
            import OpenAI from 'openai';
            import DokuMetry from 'dokumetry';

            const openai = new OpenAI({
              apiKey: 'My API Key', // defaults to process.env["OPENAI_API_KEY"]
            });

            // Pass the above `openai` object along with your DOKU URL and API key and this will make sure that all OpenAI calls are automatically tracked.
            DokuMetry.init({llm: openai, dokuUrl: "YOUR_DOKU_URL", apiKey: "YOUR_DOKU_TOKEN"})

            async function main() {
              const chatCompletion = await openai.chat.completions.create({
                messages: [{ role: 'user', content: 'What are the key to effective observability?' }],
                model: 'gpt-3.5-turbo',
              });
            }

            main();
            ```

            Refer to the `dokumetry` [NodeJS SDK repository](https://github.com/dokulabs/dokumetry-node) for more advanced configurations and use cases.
          </Step>
        </Steps>
      </Tab>
    </Tabs>
  </Step>
</Steps>

You're all set! Following these steps should have you on your way to effectively monitoring your LLM applications. If you have any questions or need support, reach out to our [community](https://join.slack.com/t/doku-0tq5728/shared_invite/zt-2a9aql9xx-FN5EIZ2DtZ~XtJoYdxUDtA).

---

<CardGroup cols={2}>
<Card title="Integrations" href="/0.0.5/integration/introduction" icon='circle-nodes'>
Integrate your LLM Provider with Doku 
</Card>
<Card title="Connections" href="/0.0.5/connections/intro" icon='link'>
Connect to your existing Observablity Platform
</Card>
</CardGroup>