---
title: 'Quickstart'
description: 'Quickly start **monitoring** your **LLM Applications** in just **a single line** of code'
icon: 'bolt'
---

This guide will walk you through setting up OpenTelemetry Auto Instrumentation for monitoring your LLM Application. In just a few steps, you'll be able to track and analyze the performance and usage of your GenAI and LLM Applications. 
In this guide, we'll show how you can send OpenTelemetry traces and metrics from your LLM Applications to Grafana Cloud

<Steps>
    <Step title="Install the OpenLIT Python SDK using pip">
      ```shell
      pip install openlit
      ```
    </Step>
    <Step title="Add the following two lines to your application code:">
      Add the snippet below to your Python application.
      
      ```python
      openlit.init(
        otlp_endpoint="https://otlp-gateway-prod-us-east-0.grafana.net/otlp", 
        otlp_headers="Authorization=Basic%20<base64 encoded Instance ID and API Token>"
      )
      ```

      Alternatively, You can also choose to set these values using `OTEL_EXPORTER_OTLP_ENDPOINT` and `OTEL_EXPORTER_OTLP_HEADERS` environment variables

      ```python
      openlit.init()
      ```

      ```env
      export OTEL_EXPORTER_OTLP_ENDPOINT = "https://otlp-gateway-prod-us-east-0.grafana.net/otlp"
      export OTEL_EXPORTER_OTLP_HEADERS = "Authorization=Basic%20<base64 encoded Instance ID and API Token>"
      ```

      Example Usage for monitoring `OpenAI` Usage:

      ```python
      from openai import OpenAI
      import openlit

      openlit.init()

      client = OpenAI(
          api_key="YOUR_OPENAI_KEY"
      )

      chat_completion = client.chat.completions.create(
          messages=[
              {
                  "role": "user",
                  "content": "What is LLM Observability",
              }
          ],
          model="gpt-3.5-turbo",
      )
      ```
      
      Refer to the OpenLIT [Python SDK repository](https://github.com/openlit/openlit/tree/main/sdk/python) for more advanced configurations and use cases.
    </Step>
    <Step title="Visualize and Analyze in Grafana">
    With the LLM Observability data now being collected and sent to your chosen OpenTelemetry backend, the next step is to visualize and analyze this data to glean insights into your application's performance, behavior, and identify areas of improvement. Here is how you would use the data in Grafana, follow these detailed instructions to explore your LLM application's Telemetry data.

    - Select the **Explore** option from Grafana's sidebar.
    - At the top, ensure the correct Tempo data source is selected from the dropdown menu.
    - Use the **Query** field to specify any particular traces you are interested in, or leave it empty to browse through all the available traces.
    - You can adjust the time range to focus on specific periods of interest.
    - Hit **Run Query** to fetch your trace data. You'll see a visual representation of your traces along with detailed information on particular spans when clicked.
    </Step>
</Steps>

You're all set! Following these steps should have you on your way to effectively monitoring your LLM applications. 

If you have any questions or need support, reach out to our [community](https://join.slack.com/t/openlit/shared_invite/zt-2etnfttwg-TjP_7BZXfYg84oAukY8QRQ).

---

<CardGroup cols={2}>
<Card title="Integrations" href="/latest/integrations/introduction" icon='circle-nodes'>
Integrate your LLM Provider with OpenLIT 
</Card>
<Card title="Connections" href="/latest/connections/intro" icon='link'>
Connect to your existing Observablity Platform
</Card>
</CardGroup>