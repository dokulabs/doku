---
title: 'Chat Completions'
description: 'Monitor Azure OpenAI `chat.completions` API usage for cost, performance & user interactions'
---

<Tabs>
  <Tab title="Python">

    ### Synchronous Usage
    <CodeGroup>
      ```python Default
      from openai import AzureOpenAI
      import dokumetry

      client = AzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      completion = client.chat.completions.create(
        model=azure_model_deployment,
        messages=[
          {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
          {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
        ]
      )

      print(completion.choices[0].message)
      ```

      ```python Streaming
      from openai import AzureOpenAI
      import dokumetry

      client = AzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      completion = client.chat.completions.create(
        model=azure_model_deployment,
        messages=[
          {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
          {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
        ],
        stream=True
      )

      for chunk in completion:
        print(chunk.choices[0].delta)
      ```

      ```python Functions
      from openai import AzureOpenAI
      import dokumetry

      client = AzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      tools = [
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and state, e.g. San Francisco, CA",
                },
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
              },
              "required": ["location"],
            },
          }
        }
      ]
      messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
      completion = client.chat.completions.create(
        model=azure_model_deployment,
        messages=messages,
        tools=tools,
        tool_choice="auto"
      )

      print(completion)
      ```

      ```python LogProbs
      from openai import AzureOpenAI
      import dokumetry

      client = AzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      completion = client.chat.completions.create(
        model=azure_model_deployment,
        messages=[
          {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
          {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
        ],
        logprobs=True,
        top_logprobs=2
      )

      print(completion.choices[0].message)
      print(completion.choices[0].logprobs)
      ```
    </CodeGroup>

    ### Asynchronous Usage

    <CodeGroup>
      ```python Default
      import asyncio
      from openai import AsyncAzureOpenAI
      import dokumetry

      client = AsyncAzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      async def main() -> None:
        chat_completion = await client.chat.completions.create(
          messages=[
            {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
            {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
          ],
          model=azure_model_deployment,
        )

      asyncio.run(main())
      ```

      ```python Streaming
      import asyncio
      from openai import AsyncAzureOpenAI
      import dokumetry

      client = AsyncAzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      async def main():
        stream = await client.chat.completions.create(
          model=azure_model_deployment,
          messages=[
            {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
            {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
          ],
          stream=True,
        )
        async for chunk in stream:
          print(chunk.choices[0].delta.content or "", end="")


      asyncio.run(main())
      ```

      ```python Functions
      import asyncio
      from openai import AsyncAzureOpenAI
      import dokumetry

      client = AsyncAzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      tools = [
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and state, e.g. San Francisco, CA",
                },
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
              },
              "required": ["location"],
            },
          }
        }
      ]
      messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]

      async def main() -> None:
        completion = await client.chat.completions.create(
          model=azure_model_deployment,
          messages=messages,
          tools=tools,
          tool_choice="auto"
        )

      asyncio.run(main())
      ```

      ```python LogProbs
      import asyncio
      from openai import AsyncAzureOpenAI
      import dokumetry

      client = AsyncAzureOpenAI(
        api_key = "YOUR_AZURE_OPENAI_API_KEY",  
        api_version = "2024-02-01",
        azure_endpoint = "YOUR_AZURE_OPENAI_API_ENDPOINT"
      )

      azure_model_deployment = "YOUR_AZURE_OPENAI_DEPLOYMENT"

      # Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
      dokumetry.init(llm=client, doku_url="YOUR_DOKU_INGESTER_URL", api_key="YOUR_DOKU_TOKEN")

      async def main() -> None:
        completion = await client.chat.completions.create(
          model=azure_model_deployment,
          messages=[
            {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
            {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
          ],
          logprobs=True,
          top_logprobs=2
        )

      asyncio.run(main())
      ```
    </CodeGroup>
  </Tab>
  <Tab title="NodeJS">
    <CodeGroup>
    ```javascript Default
    import OpenAI from "openai";
    import DokuMetry from 'dokumetry';

    const client = new OpenAI({
      apiKey: "YOUR_AZURE_OPENAI_API_KEY",
      baseURL: `https://YOUR_AZURE_OPENAI_RESOURCE.openai.azure.com/openai/deployments/YOUR_AZURE_OPENAI_DEPLOYMENT`,
      defaultQuery: { 'api-version': "2024-02-01" },
      defaultHeaders: { 'api-key': "YOUR_AZURE_OPENAI_API_KEY" },
    });

    const azureModelDeployment = 'YOUR_AZURE_OPENAI_DEPLOYMENT';

    // Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
    DokuMetry.init({llm: client, dokuUrl: "YOUR_DOKU_INGESTER_URL", apiKey: "YOUR_DOKU_TOKEN"})

    async function main() {
      const completion = await client.chat.completions.create({
        messages: [
          {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
          {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
        ],
        model: azureModelDeployment,
      });

      console.log(completion.choices[0]);
    }

    main();
    ```

    ```javascript Streaming
    import OpenAI from "openai";
    import DokuMetry from 'dokumetry';

    const client = new OpenAI({
      apiKey: "YOUR_AZURE_OPENAI_API_KEY",
      baseURL: `https://YOUR_AZURE_OPENAI_RESOURCE.openai.azure.com/openai/deployments/YOUR_AZURE_OPENAI_DEPLOYMENT`,
      defaultQuery: { 'api-version': "2024-02-01" },
      defaultHeaders: { 'api-key': "YOUR_AZURE_OPENAI_API_KEY" },
    });

    const azureModelDeployment = 'YOUR_AZURE_OPENAI_DEPLOYMENT';

    // Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
    DokuMetry.init({llm: client, dokuUrl: "YOUR_DOKU_INGESTER_URL", apiKey: "YOUR_DOKU_TOKEN"})

    async function main() {
      const completion = await client.chat.completions.create({
        model: azureModelDeployment,
        messages: [
          {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
          {"role": "user", "content": "Hello! How do I monitor my OpenAI based LLM Applications?"}
        ],
        stream: true,
      });

      for await (const chunk of completion) {
        console.log(chunk.choices[0].delta.content);
      }
    }

    main();
    ```

    ```javascript Functions
    import OpenAI from "openai";
    import DokuMetry from 'dokumetry';

    const client = new OpenAI({
      apiKey: "YOUR_AZURE_OPENAI_API_KEY",
      baseURL: `https://YOUR_AZURE_OPENAI_RESOURCE.openai.azure.com/openai/deployments/YOUR_AZURE_OPENAI_DEPLOYMENT`,
      defaultQuery: { 'api-version': "2024-02-01" },
      defaultHeaders: { 'api-key': "YOUR_AZURE_OPENAI_API_KEY" },
    });

    const azureModelDeployment = 'YOUR_AZURE_OPENAI_DEPLOYMENT';

    // Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
    DokuMetry.init({llm: client, dokuUrl: "YOUR_DOKU_INGESTER_URL", apiKey: "YOUR_DOKU_TOKEN"})

    async function main() {
      const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
      const tools = [
          {
            "type": "function",
            "function": {
              "name": "get_current_weather",
              "description": "Get the current weather in a given location",
              "parameters": {
                "type": "object",
                "properties": {
                  "location": {
                    "type": "string",
                    "description": "The city and state, e.g. San Francisco, CA",
                  },
                  "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["location"],
              },
            }
          }
      ];

      const response = await client.chat.completions.create({
        model: azureModelDeployment,
        messages: messages,
        tools: tools,
        tool_choice: "auto",
      });

      console.log(response);
    }

    main();
    ```

    ```javascript LogProbs
    import OpenAI from "openai";
    import DokuMetry from 'dokumetry';

    const client = new OpenAI({
      apiKey: "YOUR_AZURE_OPENAI_API_KEY",
      baseURL: `https://YOUR_AZURE_OPENAI_RESOURCE.openai.azure.com/openai/deployments/YOUR_AZURE_OPENAI_DEPLOYMENT`,
      defaultQuery: { 'api-version': "2024-02-01" },
      defaultHeaders: { 'api-key': "YOUR_AZURE_OPENAI_API_KEY" },
    });

    const azureModelDeployment = 'YOUR_AZURE_OPENAI_DEPLOYMENT';

    // Pass the above `client` object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.
    DokuMetry.init({llm: client, dokuUrl: "YOUR_DOKU_INGESTER_URL", apiKey: "YOUR_DOKU_TOKEN"})

    async function main() {
      const completion = await client.chat.completions.create({
        messages: [
          {"role": "system", "content": "You are a expert at monitoring LLM Applications"},
          {"role": "user", "content": "Hello! How do I monitor my Azure OpenAI based LLM Applications?"}
        ],
        model: azureModelDeployment,
        logprobs: true,
        top_logprobs: 2,
      });

      console.log(completion.choices[0]);
    }

    main();
    ```
    </CodeGroup>
  </Tab>
</Tabs>