---
title: 'Monitor LlamaIndex using OpenTelemetry'
sidebarTitle: 'LlamaIndex'
---

<Frame>
  <img src="/images/docs-llama-index-banner.gif" />
</Frame>

OpenLIT uses OpenTelemetry Auto-Instrumentation to help you monitor LLM applications built using LlamaIndex. This includes tracking performance and operation stats.

Auto-instrumentation means you don't have to set up monitoring manually for different LLMs, frameworks, or databases. By simply adding the OpenLIT in your application, all the necessary monitoring configurations are automatically set up.

## Get Started 

<Steps>
    <Step title="Install the OpenLIT Python SDK using pip">
      ```shell
      pip install openlit
      ```
    </Step>
    <Step title="Add the following two lines to your application code:">
      Add the snippet below to your Python application.
      <Tabs>
      <Tab title="Setup using function arguments">
      ```python
      import openlit

      openlit.init(otlp_endpoint="http://127.0.0.1:4318")
      ```
      
      </Tab>
      <Tab title="Setup using Environment Variables">
      ```python
      import openlit

      openlit.init()
      ```

      Run the following command to configure the OTEL export endpoint:
      ```shell
      export OTEL_EXPORTER_OTLP_ENDPOINT = "http://127.0.0.1:4318"
      ```
      </Tab>
      </Tabs>
      Refer to the OpenLIT [Python SDK repository](https://github.com/openlit/openlit/tree/main/sdk/python) for more advanced configurations and use cases.
    </Step>
</Steps>

---

<CardGroup cols={2}>
<Card title="Connections" href="/latest/connections/intro" icon='link'>
Connect to your existing Observablity Stack
</Card>
</CardGroup>