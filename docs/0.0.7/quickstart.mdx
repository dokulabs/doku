---
title: 'Quickstart'
description: 'Quickly start **monitoring** your **LLM Applications** in just **two lines** of code'
icon: 'bolt'
---

This guide will walk you through setting up monitoring for your LLM Application with minimal effort. In just a few steps, you'll be able to track and analyze the performance and usage of your Large Language Model (LLM) applications.

<Steps>
  <Step title="Deploy Doku">
    <Steps>
      <Step title="Prepare your Environment">
        ```yaml docker-compose.yml
        version: '3.8'

        services:
          clickhouse:
            image: clickhouse/clickhouse-server:24.1.5
            container_name: clickhouse
            environment:
              CLICKHOUSE_PASSWORD: ${DOKU_DB_PASSWORD:-DOKU}   
              CLICKHOUSE_USER: ${DOKU_DB_USER:-default}                   
            volumes:
              - clickhouse-data:/var/lib/clickhouse
            ports:
              - "9000:9000" 
              - "8123:8123" 
            restart: always

          doku-ingester:
            image: ghcr.io/dokulabs/doku-ingester:0.0.7
            container_name: doku-ingester
            environment:
              DOKU_DB_HOST: clickhouse   
              DOKU_DB_PORT: 9000 
              DOKU_DB_NAME: ${DOKU_DB_NAME:-default}     
              DOKU_DB_USER: ${DOKU_DB_USER:-default}              
              DOKU_DB_PASSWORD: ${DOKU_DB_PASSWORD:-DOKU}
            ports:
              - "9044:9044"           
            depends_on:
              - clickhouse
            restart: always
          
          doku-client:
            image: ghcr.io/dokulabs/doku-client:0.0.7
            container_name: doku-client
            environment:
              DATABASE_URL: file:/app/client/data/data.db
              INIT_DB_HOST: clickhouse
              INIT_DB_PORT: 8123
              INIT_DB_DATABASE: ${DOKU_DB_NAME:-default}
              INIT_DB_USERNAME: ${DOKU_DB_USER:-default}
              INIT_DB_PASSWORD: ${DOKU_DB_PASSWORD:-DOKU}
            ports:
              - "3000:3000"
            depends_on:
              - clickhouse
            volumes:
              - doku-client-data:/app/client/data
            restart: always

        volumes:
          clickhouse-data:
          doku-client-data:
        ```
      </Step>
      <Step title="Launch Doku">
        ```shell
        docker-compose up -d
        ```
      </Step>
    </Steps>
  </Step>
  <Step title="Generate an API Key">
    With Doku running, the next step is to [generate an API key](/0.0.7/api-reference/endpoint/api-keys/create) for secure communication between your applications and Doku.

    To generate your first API key, you can use the following command:

    ```shell shell
    curl --request POST \
      --url https://127.0.0.1:9044/api/keys \
      --header 'Authorization: ""' \
      --header 'Content-Type: application/json' \
      --data '{
      "name": "Patcher"
      }'
    ```

    <Note>
    **Save the API Key** â€” This key is essential for configuring the `dokumetry` SDK. 
    
    For your first API call to generate the key, the Authorization header should be left blank. However, remember to include this API key in the Authorization header for all future API interactions and SDK configurations.
    </Note>
  </Step>
  <Step title="Instrument your Application">
    Choose the appropriate SDK for your LLM application's programming language and follow the steps to integrate monitoring with just **two lines of code**.
    <Tabs>
      <Tab title="Python">
        <Steps>
          <Step title="Install the dokumetry Python SDK using pip">
            ```shell
            pip install dokumetry
            ```
          </Step>
          <Step title="Add the following two lines to your application code:">
            Add the snippet below to your Python application, replace `YOUR_DOKU_TOKEN` with API key you created in Step 2.
            
            ```python
            import dokumetry

            dokumetry.init(llm=client, doku_url="http://127.0.0.1:9044/", api_key="YOUR_DOKU_TOKEN")
            ```

            Example Usage for monitoring `OpenAI` Usage:

            ```python
            from openai import OpenAI
            import dokumetry

            client = OpenAI(
                api_key="YOUR_OPENAI_KEY"
            )

            # Pass the above `client` object along with your DOKU URL and API key and this will make sure that all OpenAI calls are automatically tracked.
            dokumetry.init(llm=client, doku_url="http://127.0.0.1:9044/", api_key="YOUR_DOKU_TOKEN")

            chat_completion = client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": "What is LLM Observability",
                    }
                ],
                model="gpt-3.5-turbo",
            )
            ```
            
            Refer to the `dokumetry` [Python SDK repository](https://github.com/dokulabs/dokumetry-python) for more advanced configurations and use cases.
          </Step>
        </Steps>
      </Tab>
      <Tab title="NodeJS">
        <Steps>
          <Step title="Install the dokumetry NodeJS SDK using npm">
            ```shell
            npm install dokumetry
            ```
          </Step>
          <Step title="Add the following two lines to your application code">
            Add the snippet below to your NodeJS application, replace `YOUR_DOKU_TOKEN` with API key you created in Step 2.
            ```javascript
            import DokuMetry from 'dokumetry';

            DokuMetry.init({llm: openai, dokuUrl: "http://127.0.0.1:9044/", apiKey: "YOUR_DOKU_TOKEN"})
            ```

            Example Usage for monitoring `OpenAI` Usage:

            ```javascript
            import OpenAI from 'openai';
            import DokuMetry from 'dokumetry';

            const openai = new OpenAI({
              apiKey: 'My API Key', // defaults to process.env["OPENAI_API_KEY"]
            });

            // Pass the above `openai` object along with your DOKU URL and API key and this will make sure that all OpenAI calls are automatically tracked.
            DokuMetry.init({llm: openai, dokuUrl: "http://127.0.0.1:9044/", apiKey: "YOUR_DOKU_TOKEN"})

            async function main() {
              const chatCompletion = await openai.chat.completions.create({
                messages: [{ role: 'user', content: 'What are the key to effective observability?' }],
                model: 'gpt-3.5-turbo',
              });
            }

            main();
            ```

            Refer to the `dokumetry` [NodeJS SDK repository](https://github.com/dokulabs/dokumetry-node) for more advanced configurations and use cases.
          </Step>
        </Steps>
      </Tab>
    </Tabs>
  </Step>
</Steps>

You're all set! Following these steps should have you on your way to effectively monitoring your LLM applications. If you have any questions or need support, reach out to our [community](https://join.slack.com/t/doku-0tq5728/shared_invite/zt-2a9aql9xx-FN5EIZ2DtZ~XtJoYdxUDtA).

---

<CardGroup cols={2}>
<Card title="Integrations" href="/0.0.7/integrations/introduction" icon='circle-nodes'>
Integrate your LLM Provider with Doku 
</Card>
<Card title="Connections" href="/0.0.7/connections/intro" icon='link'>
Connect to your existing Observablity Platform
</Card>
</CardGroup>